{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from credentials import mysql_username, mysql_password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n",
      "Dataframe succefully created\n",
      "+--------------+------------------+--------------+----------+------------+------+------+-------+-------------+-------------+\n",
      "|Application_ID|Application_Status|Credit_History|Dependents|   Education|Gender|Income|Married|Property_Area|Self_Employed|\n",
      "+--------------+------------------+--------------+----------+------------+------+------+-------+-------------+-------------+\n",
      "|      LP001002|                 Y|             1|         0|    Graduate|  Male|medium|     No|        Urban|           No|\n",
      "|      LP001003|                 N|             1|         1|    Graduate|  Male|medium|    Yes|        Rural|           No|\n",
      "|      LP001005|                 Y|             1|         0|    Graduate|  Male|   low|    Yes|        Urban|          Yes|\n",
      "|      LP001006|                 Y|             1|         0|Not Graduate|  Male|   low|    Yes|        Urban|           No|\n",
      "|      LP001008|                 Y|             1|         0|    Graduate|  Male|medium|     No|        Urban|           No|\n",
      "|      LP001011|                 Y|             1|         2|    Graduate|  Male|medium|    Yes|        Urban|          Yes|\n",
      "|      LP001013|                 Y|             1|         0|Not Graduate|  Male|   low|    Yes|        Urban|           No|\n",
      "|      LP001014|                 N|             0|        3+|    Graduate|  Male|   low|    Yes|    Semiurban|           No|\n",
      "|      LP001018|                 Y|             1|         2|    Graduate|  Male|medium|    Yes|        Urban|           No|\n",
      "|      LP001020|                 N|             1|         1|    Graduate|  Male|  high|    Yes|    Semiurban|           No|\n",
      "|      LP001024|                 Y|             1|         2|    Graduate|  Male|   low|    Yes|        Urban|           No|\n",
      "|      LP001028|                 Y|             1|         2|    Graduate|  Male|   low|    Yes|        Urban|           No|\n",
      "|      LP001029|                 N|             1|         0|    Graduate|  Male|   low|     No|        Rural|           No|\n",
      "|      LP001030|                 Y|             1|         2|    Graduate|  Male|   low|    Yes|        Urban|           No|\n",
      "|      LP001032|                 Y|             1|         0|    Graduate|  Male|medium|     No|        Urban|           No|\n",
      "|      LP001036|                 N|             0|         0|    Graduate|Female|   low|     No|        Urban|           No|\n",
      "|      LP001038|                 N|             1|         0|Not Graduate|  Male|medium|    Yes|        Rural|           No|\n",
      "|      LP001043|                 N|             0|         0|Not Graduate|  Male|medium|    Yes|        Urban|           No|\n",
      "|      LP001046|                 Y|             1|         1|    Graduate|  Male|medium|    Yes|        Urban|           No|\n",
      "|      LP001047|                 N|             0|         0|Not Graduate|  Male|   low|    Yes|    Semiurban|           No|\n",
      "+--------------+------------------+--------------+----------+------------+------+------+-------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/platformps/LoanDataset/main/loan_data.json'\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "print(f\"Status code: {response.status_code}\")\n",
    "\n",
    "spark = SparkSession.builder.appName(\"API-loan-application\").getOrCreate()\n",
    "\n",
    "# Convert the API response to an Dataframe\n",
    "df_loan_data = spark.read.json(spark.sparkContext.parallelize([data]))\n",
    "print(\"Dataframe succefully created\")\n",
    "df_loan_data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Application_ID: string (nullable = true)\n",
      " |-- Application_Status: string (nullable = true)\n",
      " |-- Credit_History: long (nullable = true)\n",
      " |-- Dependents: string (nullable = true)\n",
      " |-- Education: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Income: string (nullable = true)\n",
      " |-- Married: string (nullable = true)\n",
      " |-- Property_Area: string (nullable = true)\n",
      " |-- Self_Employed: string (nullable = true)\n",
      "\n",
      "+-------+--------------+------------------+------------------+------------------+------------+------+------+-------+-------------+-------------+\n",
      "|summary|Application_ID|Application_Status|    Credit_History|        Dependents|   Education|Gender|Income|Married|Property_Area|Self_Employed|\n",
      "+-------+--------------+------------------+------------------+------------------+------------+------+------+-------+-------------+-------------+\n",
      "|  count|           511|               511|               511|               511|         511|   511|   511|    511|          511|          511|\n",
      "|   mean|          null|              null|0.8434442270058709|0.5588865096359743|        null|  null|  null|   null|         null|         null|\n",
      "| stddev|          null|              null|0.3637375108305913|0.7904073771519635|        null|  null|  null|   null|         null|         null|\n",
      "|    min|      LP001002|                 N|                 0|                 0|    Graduate|Female|  high|     No|        Rural|           No|\n",
      "|    max|      LP002990|                 Y|                 1|                3+|Not Graduate|  Male|medium|    Yes|        Urban|          Yes|\n",
      "+-------+--------------+------------------+------------------+------------------+------------+------+------+-------+-------------+-------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loan_data.columns\n",
    "df_loan_data.printSchema()\n",
    "df_loan_data.describe().show()\n",
    "df_loan_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector as mysql\n",
    "from mysql.connector import Error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're connected to database:  ('creditcard_capstone',)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn = mysql.connect(port = '3306', database = 'creditcard_capstone', \n",
    "                        user = mysql_username, password = mysql_password)\n",
    "    if conn.is_connected():\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"select database();\")\n",
    "        record = cursor.fetchone()\n",
    "        print(\"You're connected to database: \", record)\n",
    "except Error as e:\n",
    "    print('Error while connecting to MySQL',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "1146 (42S02): Table 'creditcard_capstone.cdw_sapp_loan_application' doesn't exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMySQLInterfaceError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\fube9\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mysql\\connector\\connection_cext.py:633\u001b[0m, in \u001b[0;36mCMySQLConnection.cmd_query\u001b[1;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[0;32m    632\u001b[0m         query \u001b[39m=\u001b[39m query\u001b[39m.\u001b[39mencode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 633\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cmysql\u001b[39m.\u001b[39;49mquery(\n\u001b[0;32m    634\u001b[0m         query,\n\u001b[0;32m    635\u001b[0m         raw\u001b[39m=\u001b[39;49mraw,\n\u001b[0;32m    636\u001b[0m         buffered\u001b[39m=\u001b[39;49mbuffered,\n\u001b[0;32m    637\u001b[0m         raw_as_string\u001b[39m=\u001b[39;49mraw_as_string,\n\u001b[0;32m    638\u001b[0m         query_attrs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquery_attrs,\n\u001b[0;32m    639\u001b[0m     )\n\u001b[0;32m    640\u001b[0m \u001b[39mexcept\u001b[39;00m MySQLInterfaceError \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[1;31mMySQLInterfaceError\u001b[0m: Table 'creditcard_capstone.cdw_sapp_loan_application' doesn't exist",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fube9\\Documents\\GitHub\\Data-Engineer-Capstone-Project-\\Loan app api.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fube9/Documents/GitHub/Data-Engineer-Capstone-Project-/Loan%20app%20api.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sql_query \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mSELECT Application_Status, COUNT(*) AS Count \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fube9/Documents/GitHub/Data-Engineer-Capstone-Project-/Loan%20app%20api.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mFROM cdw_sapp_loan_application \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fube9/Documents/GitHub/Data-Engineer-Capstone-Project-/Loan%20app%20api.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mWHERE Self_employed = \u001b[39m\u001b[39m'\u001b[39m\u001b[39mYes\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fube9/Documents/GitHub/Data-Engineer-Capstone-Project-/Loan%20app%20api.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mGROUP BY Application_Status\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fube9/Documents/GitHub/Data-Engineer-Capstone-Project-/Loan%20app%20api.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m cursor\u001b[39m.\u001b[39;49mexecute(sql_query)                \u001b[39m#cursor was assigned in the connect_sql() function\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fube9/Documents/GitHub/Data-Engineer-Capstone-Project-/Loan%20app%20api.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m result \u001b[39m=\u001b[39m cursor\u001b[39m.\u001b[39mfetchall()          \u001b[39m#fetches all the results\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fube9/Documents/GitHub/Data-Engineer-Capstone-Project-/Loan%20app%20api.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m df_result \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(result)\n",
      "File \u001b[1;32mc:\\Users\\fube9\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mysql\\connector\\cursor_cext.py:330\u001b[0m, in \u001b[0;36mCMySQLCursor.execute\u001b[1;34m(self, operation, params, multi)\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[39mraise\u001b[39;00m ProgrammingError(\n\u001b[0;32m    326\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mNot all parameters were used in the SQL statement\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    327\u001b[0m             )\n\u001b[0;32m    329\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 330\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cnx\u001b[39m.\u001b[39;49mcmd_query(\n\u001b[0;32m    331\u001b[0m         stmt,\n\u001b[0;32m    332\u001b[0m         raw\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw,\n\u001b[0;32m    333\u001b[0m         buffered\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffered,\n\u001b[0;32m    334\u001b[0m         raw_as_string\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_as_string,\n\u001b[0;32m    335\u001b[0m     )\n\u001b[0;32m    336\u001b[0m \u001b[39mexcept\u001b[39;00m MySQLInterfaceError \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    337\u001b[0m     \u001b[39mraise\u001b[39;00m get_mysql_exception(\n\u001b[0;32m    338\u001b[0m         msg\u001b[39m=\u001b[39merr\u001b[39m.\u001b[39mmsg, errno\u001b[39m=\u001b[39merr\u001b[39m.\u001b[39merrno, sqlstate\u001b[39m=\u001b[39merr\u001b[39m.\u001b[39msqlstate\n\u001b[0;32m    339\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fube9\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mysql\\connector\\opentelemetry\\context_propagation.py:77\u001b[0m, in \u001b[0;36mwith_context_propagation.<locals>.wrapper\u001b[1;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Context propagation decorator.\"\"\"\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m OTEL_ENABLED \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m cnx\u001b[39m.\u001b[39motel_context_propagation:\n\u001b[1;32m---> 77\u001b[0m     \u001b[39mreturn\u001b[39;00m method(cnx, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     79\u001b[0m current_span \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39mget_current_span()\n\u001b[0;32m     80\u001b[0m tp_header \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fube9\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mysql\\connector\\connection_cext.py:641\u001b[0m, in \u001b[0;36mCMySQLConnection.cmd_query\u001b[1;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cmysql\u001b[39m.\u001b[39mquery(\n\u001b[0;32m    634\u001b[0m         query,\n\u001b[0;32m    635\u001b[0m         raw\u001b[39m=\u001b[39mraw,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    638\u001b[0m         query_attrs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquery_attrs,\n\u001b[0;32m    639\u001b[0m     )\n\u001b[0;32m    640\u001b[0m \u001b[39mexcept\u001b[39;00m MySQLInterfaceError \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 641\u001b[0m     \u001b[39mraise\u001b[39;00m get_mysql_exception(\n\u001b[0;32m    642\u001b[0m         err\u001b[39m.\u001b[39merrno, msg\u001b[39m=\u001b[39merr\u001b[39m.\u001b[39mmsg, sqlstate\u001b[39m=\u001b[39merr\u001b[39m.\u001b[39msqlstate\n\u001b[0;32m    643\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m    644\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    645\u001b[0m     addr \u001b[39m=\u001b[39m (\n\u001b[0;32m    646\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unix_socket \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unix_socket \u001b[39melse\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_host\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_port\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    647\u001b[0m     )\n",
      "\u001b[1;31mProgrammingError\u001b[0m: 1146 (42S02): Table 'creditcard_capstone.cdw_sapp_loan_application' doesn't exist"
     ]
    }
   ],
   "source": [
    "sql_query = (\"SELECT Application_Status, COUNT(*) AS Count \"\n",
    "                \"FROM cdw_sapp_loan_application \"\n",
    "                \"WHERE Self_employed = 'Yes' \"\n",
    "                \"GROUP BY Application_Status\")\n",
    "cursor.execute(sql_query)                #cursor was assigned in the connect_sql() function\n",
    "result = cursor.fetchall()          #fetches all the results\n",
    "df_result = pd.DataFrame(result)\n",
    "df_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o852.save.\n: java.sql.SQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '-sapp_loan_application (`Application_ID` TEXT , `Application_Status` TEXT , `Cre' at line 1\r\n\tat com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:120)\r\n\tat com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)\r\n\tat com.mysql.cj.jdbc.StatementImpl.executeUpdateInternal(StatementImpl.java:1333)\r\n\tat com.mysql.cj.jdbc.StatementImpl.executeLargeUpdate(StatementImpl.java:2106)\r\n\tat com.mysql.cj.jdbc.StatementImpl.executeUpdate(StatementImpl.java:1243)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.executeStatement(JdbcUtils.scala:1083)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.createTable(JdbcUtils.scala:913)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:81)\r\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\r\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:578)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1623)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fube9\\Documents\\GitHub\\Data-Engineer-Capstone-Project-\\Capstone-3-loan api.ipynb Cell 6\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fube9/Documents/GitHub/Data-Engineer-Capstone-Project-/Capstone-3-loan%20api.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Write the DataFrame into MySQL\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fube9/Documents/GitHub/Data-Engineer-Capstone-Project-/Capstone-3-loan%20api.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_loan_data\u001b[39m.\u001b[39;49mwrite\u001b[39m.\u001b[39;49mformat(\u001b[39m\"\u001b[39;49m\u001b[39mjdbc\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fube9/Documents/GitHub/Data-Engineer-Capstone-Project-/Capstone-3-loan%20api.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   \u001b[39m.\u001b[39;49mmode(\u001b[39m\"\u001b[39;49m\u001b[39mappend\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fube9/Documents/GitHub/Data-Engineer-Capstone-Project-/Capstone-3-loan%20api.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m   \u001b[39m.\u001b[39;49moption(\u001b[39m\"\u001b[39;49m\u001b[39murl\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mjdbc:mysql://localhost:3306/creditcard_capstone\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fube9/Documents/GitHub/Data-Engineer-Capstone-Project-/Capstone-3-loan%20api.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   \u001b[39m.\u001b[39;49moption(\u001b[39m\"\u001b[39;49m\u001b[39mdbtable\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcreditcard_capstone.cdw-sapp_loan_application\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fube9/Documents/GitHub/Data-Engineer-Capstone-Project-/Capstone-3-loan%20api.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m   \u001b[39m.\u001b[39;49moption(\u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mroot\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fube9/Documents/GitHub/Data-Engineer-Capstone-Project-/Capstone-3-loan%20api.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   \u001b[39m.\u001b[39;49moption(\u001b[39m\"\u001b[39;49m\u001b[39mpassword\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mpassword\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fube9/Documents/GitHub/Data-Engineer-Capstone-Project-/Capstone-3-loan%20api.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   \u001b[39m.\u001b[39;49msave()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fube9/Documents/GitHub/Data-Engineer-Capstone-Project-/Capstone-3-loan%20api.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Stop the Spark session\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fube9/Documents/GitHub/Data-Engineer-Capstone-Project-/Capstone-3-loan%20api.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# spark.stop()\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fube9\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\readwriter.py:1396\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[1;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[0;32m   1394\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mformat\u001b[39m)\n\u001b[0;32m   1395\u001b[0m \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1396\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jwrite\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1397\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1398\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jwrite\u001b[39m.\u001b[39msave(path)\n",
      "File \u001b[1;32mc:\\Users\\fube9\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\fube9\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeco\u001b[39m(\u001b[39m*\u001b[39ma: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    168\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39ma, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    170\u001b[0m     \u001b[39mexcept\u001b[39;00m Py4JJavaError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    171\u001b[0m         converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mc:\\Users\\fube9\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[39m=\u001b[39m OUTPUT_CONVERTER[\u001b[39mtype\u001b[39m](answer[\u001b[39m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m answer[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o852.save.\n: java.sql.SQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '-sapp_loan_application (`Application_ID` TEXT , `Application_Status` TEXT , `Cre' at line 1\r\n\tat com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:120)\r\n\tat com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)\r\n\tat com.mysql.cj.jdbc.StatementImpl.executeUpdateInternal(StatementImpl.java:1333)\r\n\tat com.mysql.cj.jdbc.StatementImpl.executeLargeUpdate(StatementImpl.java:2106)\r\n\tat com.mysql.cj.jdbc.StatementImpl.executeUpdate(StatementImpl.java:1243)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.executeStatement(JdbcUtils.scala:1083)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.createTable(JdbcUtils.scala:913)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:81)\r\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\r\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\r\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:578)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1623)\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Write the DataFrame into MySQL\n",
    "df_loan_data.write.format(\"jdbc\") \\\n",
    "  .mode(\"append\") \\\n",
    "  .option(\"url\", \"jdbc:mysql://localhost:3306/creditcard_capstone\") \\\n",
    "  .option(\"dbtable\", \"creditcard_capstone.cdw-sapp_loan_application\") \\\n",
    "  .option(\"user\", \"root\") \\\n",
    "  .option(\"password\", \"password\") \\\n",
    "  .save()\n",
    "\n",
    "# Stop the Spark session\n",
    "# spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
